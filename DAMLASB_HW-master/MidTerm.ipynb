{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAMLAS MidTerm Exam\n",
    "10:00AM - 12:00PM(CT) September 6, 2016\n",
    "Midterm\n",
    "\n",
    "#### Data Analytics and Machine Learning at Scale\n",
    "\n",
    "##### Target, Bangalore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Please insert your contact information here\n",
    "###### Insert you name here\n",
    "Manish Rai\n",
    "\n",
    "manish.rai@target.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from __future__ import division\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MT1. Which of the following statememts about map-reduce are true?\n",
    "(I) If you only have 1 computer with 1 computing core, then map-reduce is unlikely to help\n",
    "\n",
    "(II) If we run map-reduce using N single-core computers, then it is likely to get at least an N-Fold speedup compared to using 1 computer\n",
    "\n",
    "(III) Because of network latency and other overhead associated with map-reduce, if we run map-reduce using N computers, then we will get less than N-Fold speedup compared to using 1 computer\n",
    "\n",
    "(IV) When using map-reduce for learning a naive Bayes classifier for SPAM classification, we usually use a single machine that accumulates the partial class and word stats from each of the map machines, in order to compute the final model.\n",
    "\n",
    "Please select one from the following that is most correct:\n",
    "\n",
    "(a) I, II, III, IV\n",
    "\n",
    "(b) I, III, IV\n",
    "\n",
    "(c) I, III\n",
    "\n",
    "(d) I,II, III"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MT2. normalized product co-occurrence\n",
    "Suppose you wish to write a MapReduce job that creates normalized product co-occurrence (i.e., pairs of products that have been purchased together) data form a large transaction file of shopping baskets. In addition, we want the relative frequency of coocurring products. Given this scenario, to ensure that all (potentially many) reducers receive appropriate normalization factors (denominators)for a product in the most effcient order in their input streams (so as to minimize memory overhead on the reducer side), the mapper should emit/yield records according to which pattern for the product occurence totals:\n",
    "\n",
    "(a) emit (*,product) count\n",
    "\n",
    "(b) There is no need to use order inversion here\n",
    "\n",
    "(c) emit (product,*) count\n",
    "\n",
    "(d) None of the above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MT3. What is the input to the Reduce function in MRJob? Select the most correct choice.\n",
    "(a) An arbitrarily sized list of key/value pairs.\n",
    "\n",
    "(b) One key and a list of some values associated with that key\n",
    "\n",
    "(c) One key and a list of all values associated with that key.\n",
    "\n",
    "(d) None of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing kltext.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile kltext.txt\n",
    "1.Data Science is an interdisciplinary field about processes and systems to extract knowledge or insights from large volumes of data in various forms (data in various forms, data in various forms, data in various forms), either structured or unstructured,[1][2] which is a continuation of some of the data analysis fields such as statistics, data mining and predictive analytics, as well as Knowledge Discovery in Databases.\n",
    "2.Machine learning is a subfield of computer science[1] that evolved from the study of pattern recognition and computational learning theory in artificial intelligence.[1] Machine learning explores the study and construction of algorithms that can learn from and make predictions on data.[2] Such algorithms operate by building a model from example inputs in order to make data-driven predictions or decisions,[3]:2 rather than following strictly static program instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.Data Science is an interdisciplinary field about processes and systems to extract knowledge or insights from large volumes of data in various forms (data in various forms, data in various forms, data in various forms), either structured or unstructured,[1][2] which is a continuation of some of the data analysis fields such as statistics, data mining and predictive analytics, as well as Knowledge Discovery in Databases.\r\n",
      "2.Machine learning is a subfield of computer science[1] that evolved from the study of pattern recognition and computational learning theory in artificial intelligence.[1] Machine learning explores the study and construction of algorithms that can learn from and make predictions on data.[2] Such algorithms operate by building a model from example inputs in order to make data-driven predictions or decisions,[3]:2 rather than following strictly static program instructions."
     ]
    }
   ],
   "source": [
    "!cat kltext.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting kldivergence.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile kldivergence.py\n",
    "from __future__ import division\n",
    "from mrjob.job import MRJob\n",
    "import re, math\n",
    "import numpy as np\n",
    "class kldivergence(MRJob):\n",
    "    \n",
    "    # process each string character by character\n",
    "    # the relative frequency of each character emitting Pr(character|str)\n",
    "    # for input record 1.abcbe\n",
    "    # emit \"a\"    [1, 0.2]\n",
    "    # emit \"b\"    [1, 0.4] etc...\n",
    "    def mapper1(self, _, line):\n",
    "        index = int(line.split('.',1)[0])\n",
    "        letter_list = re.sub(r\"[^A-Za-z]+\", '', line).lower()\n",
    "        count = {}\n",
    "        for l in letter_list:\n",
    "            if count.has_key(l):\n",
    "                count[l] += 1\n",
    "            else:\n",
    "                count[l] = 1\n",
    "        for key in count:\n",
    "            yield key, [index, count[key]*1.0/len(letter_list)]\n",
    "\n",
    "\n",
    "    def reducer1(self, key, values):\n",
    "        p = 0\n",
    "        q = 0\n",
    "        for v in values:\n",
    "            if v[0] == 1:  #String 1\n",
    "                p = v[1]\n",
    "            else:          # String 2\n",
    "                q = v[1]\n",
    "                \n",
    "        yield p*np.log(p/q)\n",
    "\n",
    "    #Aggegate components            \n",
    "    def reducer2(self, key, values):\n",
    "        kl_sum = 0\n",
    "        for value in values:\n",
    "            kl_sum = kl_sum + value\n",
    "        yield \"KLDivergence\", kl_sum\n",
    "            \n",
    "    def steps(self):\n",
    "        return [self.mr(mapper=self.mapper1,\n",
    "                        reducer=self.reducer1),\n",
    "                \n",
    "                self.mr(reducer=self.reducer2)\n",
    "               \n",
    "               ]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    kldivergence.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /var/folders/3h/lfpv5ykj6414h50t_n_nfv28f2dtvc/T/kldivergence.z00193k.20160906.053448.015442\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "Running step 1 of 2...\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"kldivergence.py\", line 52, in <module>\n",
      "    kldivergence.run()\n",
      "  File \"/Users/z00193k/anaconda/lib/python2.7/site-packages/mrjob/job.py\", line 429, in run\n",
      "    mr_job.execute()\n",
      "  File \"/Users/z00193k/anaconda/lib/python2.7/site-packages/mrjob/job.py\", line 447, in execute\n",
      "    super(MRJob, self).execute()\n",
      "  File \"/Users/z00193k/anaconda/lib/python2.7/site-packages/mrjob/launch.py\", line 158, in execute\n",
      "    self.run_job()\n",
      "  File \"/Users/z00193k/anaconda/lib/python2.7/site-packages/mrjob/launch.py\", line 228, in run_job\n",
      "    runner.run()\n",
      "  File \"/Users/z00193k/anaconda/lib/python2.7/site-packages/mrjob/runner.py\", line 481, in run\n",
      "    self._run()\n",
      "  File \"/Users/z00193k/anaconda/lib/python2.7/site-packages/mrjob/sim.py\", line 199, in _run\n",
      "    self._invoke_step(step_num, 'reducer')\n",
      "  File \"/Users/z00193k/anaconda/lib/python2.7/site-packages/mrjob/sim.py\", line 273, in _invoke_step\n",
      "    working_dir, env)\n",
      "  File \"/Users/z00193k/anaconda/lib/python2.7/site-packages/mrjob/inline.py\", line 154, in _run_step\n",
      "    child_instance.execute()\n",
      "  File \"/Users/z00193k/anaconda/lib/python2.7/site-packages/mrjob/job.py\", line 444, in execute\n",
      "    self.run_reducer(self.options.step_num)\n",
      "  File \"/Users/z00193k/anaconda/lib/python2.7/site-packages/mrjob/job.py\", line 549, in run_reducer\n",
      "    for out_key, out_value in reducer(key, values) or ():\n",
      "  File \"kldivergence.py\", line 34, in reducer1\n",
      "    yield p*np.log(p/q)\n",
      "ZeroDivisionError: float division by zero\n"
     ]
    }
   ],
   "source": [
    "!python kldivergence.py kltext.txt \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Non-ASCII character '\\xe2' in file kldivergence.py on line 25, but no encoding declared; see http://python.org/dev/peps/pep-0263/ for details (kldivergence.py, line 25)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"kldivergence.py\"\u001b[0;36m, line \u001b[0;32m25\u001b[0m\n\u001b[0;31m    # Kullback–Leibler divergence of Q from P is defined\u001b[0m\n\u001b[0m                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Non-ASCII character '\\xe2' in file kldivergence.py on line 25, but no encoding declared; see http://python.org/dev/peps/pep-0263/ for details\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from mrjob.job import MRJob\n",
    "from kldivergence import kldivergence\n",
    "\n",
    "#dont forget to save kltext.txt (see earlier cell)\n",
    "mr_job = kldivergence(args=['kltext.txt'])\n",
    "with mr_job.make_runner() as runner: \n",
    "    runner.run()\n",
    "    # stream_output: get access of the output \n",
    "    for line in runner.stream_output():\n",
    "        print mr_job.parse_output_line(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/z00193k/Dropbox/DataScienceProgram/DAMLASB_HW\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
