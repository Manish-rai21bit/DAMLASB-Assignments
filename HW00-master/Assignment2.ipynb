{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cloudera/Dropbox/DataScienceProgram/Day2\n"
     ]
    }
   ],
   "source": [
    "%cd /home/cloudera/Dropbox/DataScienceProgram/Day2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!mkdir HWDay2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cloudera/Dropbox/DataScienceProgram/Day2/HWDay2\n"
     ]
    }
   ],
   "source": [
    "%cd HWDay2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cloudera/Dropbox/DataScienceProgram/Day2/HWDay2\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#3. HW2.1 \n",
    "#Change the mapper.py/reducer.py combination from the the above wordcount example so that you get \n",
    "#the longest word present in the Alice Book (from HW1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  163k  100  163k    0     0  41487      0  0:00:04  0:00:04 --:--:-- 45447\n"
     ]
    }
   ],
   "source": [
    "!curl 'http://www.gutenberg.org/cache/epub/11/pg11.txt' -o alicesTExtFilename.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿Project Gutenberg's Alice's Adventures in Wonderland, by Lewis Carroll\r",
      "\r\n",
      "\r",
      "\r\n",
      "This eBook is for the use of anyone anywhere at no cost and with\r",
      "\r\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\r",
      "\r\n",
      "re-use it under the terms of the Project Gutenberg License included\r",
      "\r\n",
      "with this eBook or online at www.gutenberg.org\r",
      "\r\n",
      "\r",
      "\r\n",
      "\r",
      "\r\n",
      "Title: Alice's Adventures in Wonderland\r",
      "\r\n",
      "\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head alicesTExtFilename.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapper1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper1.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import sys\n",
    "#sys.stderr.write(\"reporter:counter:Tokens,Total,1\") # NOTE missing the carriage return so wont work\n",
    "sys.stderr.write(\"reporter:counter:Mapper Counters,Calls,1\\n\")\n",
    "sys.stderr.write(\"reporter:status:processing my message...how are  you\\n\")\n",
    "\n",
    "wordLen=0\n",
    "wordLong=None\n",
    "\n",
    "for line in sys.stdin:\n",
    "    #This removes the whitespaces\n",
    "    line = line.strip()\n",
    "    #getting words from line\n",
    "    words=line.split()\n",
    "    #getting words and their counts\n",
    "    for word in words:\n",
    "        if len(word)>wordLen:\n",
    "            wordLen=len(word)\n",
    "            wordLong=word\n",
    "              \n",
    "    print ('%05d\\t%s') % (wordLen, wordLong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!chmod a+x reducer1.py\n",
    "!chmod a+x mapper1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: mapper1.py: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!echo \"You are my world bro\" | mapper1.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducer1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer1.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import sys\n",
    "\n",
    "curmax_wordLen = 0\n",
    "curmax_wordLong = None\n",
    "sys.stderr.write(\"reporter:counter:Reducer Counters,Calls,1\\n\")\n",
    "\n",
    "for line in sys.stdin:\n",
    "    line = line.split()\n",
    "    wordLen, wordLong = line.split('\\t', 1)\n",
    "    \n",
    "    if wordLen>curmax_wordLen:\n",
    "        curmax_wordLen=wordLen\n",
    "        curmax_wordLong=wordLong\n",
    "            \n",
    "print ('%s\\t%s') % (curmax_wordLong, curmax_wordLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted alicesTExtFilename.txt\n",
      "rm: `curmax_wordLen-output': No such file or directory\n",
      "16/08/31 11:13:13 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n",
      "packageJobJar: [/home/cloudera/Dropbox/DataScienceProgram/Day2/HWDay2/mapper1.py, /home/cloudera/Dropbox/DataScienceProgram/Day2/HWDay2/reducer1.py] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.8.0.jar] /tmp/streamjob6368756509374150966.jar tmpDir=null\n",
      "16/08/31 11:13:14 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "16/08/31 11:13:14 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "16/08/31 11:13:15 INFO mapred.FileInputFormat: Total input paths to process : 1\n",
      "16/08/31 11:13:15 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "16/08/31 11:13:15 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1472467579313_0017\n",
      "16/08/31 11:13:15 INFO impl.YarnClientImpl: Submitted application application_1472467579313_0017\n",
      "16/08/31 11:13:15 INFO mapreduce.Job: The url to track the job: http://quickstart.cloudera:8088/proxy/application_1472467579313_0017/\n",
      "16/08/31 11:13:15 INFO mapreduce.Job: Running job: job_1472467579313_0017\n",
      "16/08/31 11:13:21 INFO mapreduce.Job: Job job_1472467579313_0017 running in uber mode : false\n",
      "16/08/31 11:13:21 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "16/08/31 11:13:25 INFO mapreduce.Job: Task Id : attempt_1472467579313_0017_m_000000_0, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:325)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:538)\n",
      "\tat org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)\n",
      "\tat org.apache.hadoop.mapred.Task$OldCombinerRunner.combine(Task.java:1635)\n",
      "\tat org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1634)\n",
      "\tat org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1486)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:460)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1693)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\n",
      "\n",
      "16/08/31 11:13:25 INFO mapreduce.Job: Task Id : attempt_1472467579313_0017_m_000001_0, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:325)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:538)\n",
      "\tat org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)\n",
      "\tat org.apache.hadoop.mapred.Task$OldCombinerRunner.combine(Task.java:1635)\n",
      "\tat org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1634)\n",
      "\tat org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1486)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:460)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1693)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\n",
      "\n",
      "16/08/31 11:13:28 INFO mapreduce.Job: Task Id : attempt_1472467579313_0017_m_000000_1, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:325)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:538)\n",
      "\tat org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)\n",
      "\tat org.apache.hadoop.mapred.Task$OldCombinerRunner.combine(Task.java:1635)\n",
      "\tat org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1634)\n",
      "\tat org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1486)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:460)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1693)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\n",
      "\n",
      "16/08/31 11:13:29 INFO mapreduce.Job: Task Id : attempt_1472467579313_0017_m_000001_1, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:325)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:538)\n",
      "\tat org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)\n",
      "\tat org.apache.hadoop.mapred.Task$OldCombinerRunner.combine(Task.java:1635)\n",
      "\tat org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1634)\n",
      "\tat org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1486)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:460)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1693)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\n",
      "\n",
      "16/08/31 11:13:35 INFO mapreduce.Job: Task Id : attempt_1472467579313_0017_m_000000_2, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:325)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:538)\n",
      "\tat org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)\n",
      "\tat org.apache.hadoop.mapred.Task$OldCombinerRunner.combine(Task.java:1635)\n",
      "\tat org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1634)\n",
      "\tat org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1486)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:460)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1693)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\n",
      "\n",
      "16/08/31 11:13:36 INFO mapreduce.Job: Task Id : attempt_1472467579313_0017_m_000001_2, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:325)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:538)\n",
      "\tat org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:134)\n",
      "\tat org.apache.hadoop.mapred.Task$OldCombinerRunner.combine(Task.java:1635)\n",
      "\tat org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1634)\n",
      "\tat org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1486)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:460)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1693)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\n",
      "\n",
      "16/08/31 11:13:39 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "16/08/31 11:13:40 INFO mapreduce.Job: Job job_1472467579313_0017 failed with state FAILED due to: Task failed task_1472467579313_0017_m_000000\n",
      "Job failed as tasks failed. failedMaps:1 failedReduces:0\n",
      "\n",
      "16/08/31 11:13:40 INFO mapreduce.Job: Counters: 14\n",
      "\tJob Counters \n",
      "\t\tFailed map tasks=7\n",
      "\t\tKilled map tasks=1\n",
      "\t\tKilled reduce tasks=3\n",
      "\t\tLaunched map tasks=8\n",
      "\t\tOther local map tasks=6\n",
      "\t\tData-local map tasks=2\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=21171\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=0\n",
      "\t\tTotal time spent by all map tasks (ms)=21171\n",
      "\t\tTotal vcore-seconds taken by all map tasks=21171\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=21679104\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=0\n",
      "\t\tPhysical memory (bytes) snapshot=0\n",
      "\t\tVirtual memory (bytes) snapshot=0\n",
      "16/08/31 11:13:40 ERROR streaming.StreamJob: Job not successful!\n",
      "Streaming Command Failed!\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm alicesTExtFilename.txt \n",
    "!hdfs dfs -copyFromLocal alicesTExtFilename.txt \n",
    "!hdfs dfs -rm -r curmax_wordLen-output\n",
    "#usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/tools/lib\n",
    "dataDir = \"/home/cloudera/Dropbox/DataScienceProgram/Day2/HWDay2/\"\n",
    "\n",
    "!hadoop jar /usr/lib/hadoop-0.20-mapreduce/contrib/streaming/hadoop-streaming-2.6.0-mr1-cdh5.8.0.jar \\\n",
    "   -file \"/home/cloudera/Dropbox/DataScienceProgram/Day2/HWDay2/mapper1.py\" \\\n",
    "   -mapper /home/cloudera/Dropbox/DataScienceProgram/Day2/HWDay2/mapper1.py \\\n",
    "   -file \"/home/cloudera/Dropbox/DataScienceProgram/Day2/HWDay2/reducer1.py\" \\\n",
    "   -reducer /home/cloudera/Dropbox/DataScienceProgram/Day2/HWDay2/reducer1.py \\\n",
    "   -combiner /home/cloudera/Dropbox/DataScienceProgram/Day2/HWDay2/reducer1.py \\\n",
    "   -input alicesTExtFilename.txt \\\n",
    "   -output curmax_wordLen-output  \\\n",
    "   -numReduceTasks 3\n",
    "   #--D mapreduce.job.reduces=2  depecated\n",
    "#-input historical_tours.txt  file on Hadoop\n",
    "\n",
    "\n",
    "#output directory on Hadoop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3. HW2.2\n",
    "Change the mapper.py/reducer.py combination so that you get only the number of words starting with an uppercase letter, \n",
    "and the number of words starting with a lowercase letter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapperupper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapperupper.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import sys\n",
    "#sys.stderr.write(\"reporter:counter:Tokens,Total,1\") # NOTE missing the carriage return so wont work\n",
    "sys.stderr.write(\"reporter:counter:Mapper Counters,Calls,1\\n\")\n",
    "sys.stderr.write(\"reporter:status:processing my message...how are  you\\n\")\n",
    "\n",
    "Upper_Case = 0\n",
    "Lower_Case = 0\n",
    "for line in sys.stdin:\n",
    "    for line in sys.stdin:\n",
    "    for word in line.split():\n",
    "        if word[0].isupper:\n",
    "        print '%s\\t%d' % (word, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapperlower.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapperlower.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import sys\n",
    "#sys.stderr.write(\"reporter:counter:Tokens,Total,1\") # NOTE missing the carriage return so wont work\n",
    "sys.stderr.write(\"reporter:counter:Mapper Counters,Calls,1\\n\")\n",
    "sys.stderr.write(\"reporter:status:processing my message...how are  you\\n\")\n",
    "\n",
    "Upper_Case = 0\n",
    "Lower_Case = 0\n",
    "for line in sys.stdin:\n",
    "    for line in sys.stdin:\n",
    "    for word in line.split():\n",
    "        if word[0].islower:\n",
    "        print '%s\\t%d' % (word, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing reducer2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer2.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import sys\n",
    "\n",
    "cur_key = None\n",
    "cur_count = 0\n",
    "sys.stderr.write(\"reporter:counter:Reducer Counters,Calls,1\\n\")\n",
    "for line in sys.stdin:\n",
    "    key, value = line.split()\n",
    "    if key == cur_key:\n",
    "        cur_count += int(value)\n",
    "    else:\n",
    "        if cur_key:\n",
    "            print '%s\\t%s' % (cur_key, cur_count)\n",
    "        cur_key = key\n",
    "        cur_count = int(value)\n",
    "\n",
    "print '%s\\t%s' % (cur_key, cur_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted alicesTExtFilename.txt\n",
      "Deleted cur_key-output\n",
      "16/08/31 11:21:52 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n",
      "packageJobJar: [/home/cloudera/Dropbox/DataScienceProgram/Day2/HWDay2/mapperupper.py, /home/cloudera/Dropbox/DataScienceProgram/Day2/HWDay2/reducer2.py] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.8.0.jar] /tmp/streamjob2882959984729867381.jar tmpDir=null\n",
      "16/08/31 11:21:53 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "16/08/31 11:21:53 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "16/08/31 11:21:53 INFO mapred.FileInputFormat: Total input paths to process : 1\n",
      "16/08/31 11:21:53 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "16/08/31 11:21:54 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1472467579313_0019\n",
      "16/08/31 11:21:54 INFO impl.YarnClientImpl: Submitted application application_1472467579313_0019\n",
      "16/08/31 11:21:54 INFO mapreduce.Job: The url to track the job: http://quickstart.cloudera:8088/proxy/application_1472467579313_0019/\n",
      "16/08/31 11:21:54 INFO mapreduce.Job: Running job: job_1472467579313_0019\n",
      "16/08/31 11:21:59 INFO mapreduce.Job: Job job_1472467579313_0019 running in uber mode : false\n",
      "16/08/31 11:21:59 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "16/08/31 11:22:02 INFO mapreduce.Job: Task Id : attempt_1472467579313_0019_m_000000_0, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:325)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:538)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:453)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1693)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\n",
      "\n",
      "16/08/31 11:22:03 INFO mapreduce.Job: Task Id : attempt_1472467579313_0019_m_000001_0, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:325)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:538)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:453)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1693)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\n",
      "\n",
      "16/08/31 11:22:06 INFO mapreduce.Job: Task Id : attempt_1472467579313_0019_m_000000_1, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:325)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:538)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:453)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1693)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\n",
      "\n",
      "16/08/31 11:22:08 INFO mapreduce.Job: Task Id : attempt_1472467579313_0019_m_000001_1, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:325)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:538)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:453)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1693)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\n",
      "\n",
      "16/08/31 11:22:12 INFO mapreduce.Job: Task Id : attempt_1472467579313_0019_m_000000_2, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:325)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:538)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:453)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1693)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\n",
      "\n",
      "16/08/31 11:22:13 INFO mapreduce.Job: Task Id : attempt_1472467579313_0019_m_000001_2, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:325)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:538)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:453)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1693)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\n",
      "\n",
      "16/08/31 11:22:16 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "16/08/31 11:22:17 INFO mapreduce.Job: Job job_1472467579313_0019 failed with state FAILED due to: Task failed task_1472467579313_0019_m_000000\n",
      "Job failed as tasks failed. failedMaps:1 failedReduces:0\n",
      "\n",
      "16/08/31 11:22:17 INFO mapreduce.Job: Counters: 14\n",
      "\tJob Counters \n",
      "\t\tFailed map tasks=7\n",
      "\t\tKilled map tasks=1\n",
      "\t\tKilled reduce tasks=3\n",
      "\t\tLaunched map tasks=8\n",
      "\t\tOther local map tasks=6\n",
      "\t\tData-local map tasks=2\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=19803\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=0\n",
      "\t\tTotal time spent by all map tasks (ms)=19803\n",
      "\t\tTotal vcore-seconds taken by all map tasks=19803\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=20278272\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=0\n",
      "\t\tPhysical memory (bytes) snapshot=0\n",
      "\t\tVirtual memory (bytes) snapshot=0\n",
      "16/08/31 11:22:17 ERROR streaming.StreamJob: Job not successful!\n",
      "Streaming Command Failed!\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm alicesTExtFilename.txt \n",
    "!hdfs dfs -copyFromLocal alicesTExtFilename.txt \n",
    "!hdfs dfs -rm -r cur_key-output\n",
    "#usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/tools/lib\n",
    "dataDir = \"/home/cloudera/Dropbox/DataScienceProgram/Day2\"\n",
    "\n",
    "!hadoop jar /usr/lib/hadoop-0.20-mapreduce/contrib/streaming/hadoop-streaming-2.6.0-mr1-cdh5.8.0.jar \\\n",
    "   -file \"/home/cloudera/Dropbox/DataScienceProgram/Day2/HWDay2/mapperupper.py\" \\\n",
    "   -mapper /home/cloudera/Dropbox/DataScienceProgram/Day2/HWDay2/mapperupper.py \\\n",
    "   -file \"/home/cloudera/Dropbox/DataScienceProgram/Day2/HWDay2/reducer2.py\" \\\n",
    "   -reducer /home/cloudera/Dropbox/DataScienceProgram/Day2/HWDay2/reducer2.py \\\n",
    "   -combiner /home/cloudera/Dropbox/DataScienceProgram/Day2/HWDay2/reducer2.py \\\n",
    "   -input alicesTExtFilename.txt \\\n",
    "   -output cur_key-output  \\\n",
    "   -numReduceTasks 3\n",
    "   #--D mapreduce.job.reduces=2  depecated\n",
    "#-input historical_tours.txt  file on Hadoop\n",
    "\n",
    "\n",
    "#output directory on Hadoop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted alicesTExtFilename.txt\n",
      "Deleted cur_key-output\n",
      "16/08/31 11:23:05 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n",
      "packageJobJar: [/home/cloudera/Dropbox/DataScienceProgram/Day2/HWDay2/mapperlower.py, /home/cloudera/Dropbox/DataScienceProgram/Day2/HWDay2/reducer2.py] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.8.0.jar] /tmp/streamjob7673215411723592499.jar tmpDir=null\n",
      "16/08/31 11:23:06 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "16/08/31 11:23:06 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "16/08/31 11:23:07 INFO mapred.FileInputFormat: Total input paths to process : 1\n",
      "16/08/31 11:23:07 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "16/08/31 11:23:07 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1472467579313_0020\n",
      "16/08/31 11:23:07 INFO impl.YarnClientImpl: Submitted application application_1472467579313_0020\n",
      "16/08/31 11:23:07 INFO mapreduce.Job: The url to track the job: http://quickstart.cloudera:8088/proxy/application_1472467579313_0020/\n",
      "16/08/31 11:23:07 INFO mapreduce.Job: Running job: job_1472467579313_0020\n",
      "16/08/31 11:23:12 INFO mapreduce.Job: Job job_1472467579313_0020 running in uber mode : false\n",
      "16/08/31 11:23:12 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "16/08/31 11:23:16 INFO mapreduce.Job: Task Id : attempt_1472467579313_0020_m_000000_0, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:325)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:538)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:453)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1693)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\n",
      "\n",
      "16/08/31 11:23:17 INFO mapreduce.Job: Task Id : attempt_1472467579313_0020_m_000001_0, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:325)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:538)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:453)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1693)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\n",
      "\n",
      "16/08/31 11:23:21 INFO mapreduce.Job: Task Id : attempt_1472467579313_0020_m_000000_1, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:325)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:538)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:453)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1693)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\n",
      "\n",
      "16/08/31 11:23:22 INFO mapreduce.Job: Task Id : attempt_1472467579313_0020_m_000001_1, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:325)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:538)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:453)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1693)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\n",
      "\n",
      "16/08/31 11:23:27 INFO mapreduce.Job: Task Id : attempt_1472467579313_0020_m_000000_2, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:325)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:538)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:453)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1693)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\n",
      "\n",
      "16/08/31 11:23:28 INFO mapreduce.Job: Task Id : attempt_1472467579313_0020_m_000001_2, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:325)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:538)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:453)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1693)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\n",
      "\n",
      "16/08/31 11:23:33 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "16/08/31 11:23:33 INFO mapreduce.Job: Job job_1472467579313_0020 failed with state FAILED due to: Task failed task_1472467579313_0020_m_000000\n",
      "Job failed as tasks failed. failedMaps:1 failedReduces:0\n",
      "\n",
      "16/08/31 11:23:33 INFO mapreduce.Job: Counters: 14\n",
      "\tJob Counters \n",
      "\t\tFailed map tasks=7\n",
      "\t\tKilled map tasks=1\n",
      "\t\tKilled reduce tasks=3\n",
      "\t\tLaunched map tasks=8\n",
      "\t\tOther local map tasks=6\n",
      "\t\tData-local map tasks=2\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=24655\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=0\n",
      "\t\tTotal time spent by all map tasks (ms)=24655\n",
      "\t\tTotal vcore-seconds taken by all map tasks=24655\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=25246720\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=0\n",
      "\t\tPhysical memory (bytes) snapshot=0\n",
      "\t\tVirtual memory (bytes) snapshot=0\n",
      "16/08/31 11:23:33 ERROR streaming.StreamJob: Job not successful!\n",
      "Streaming Command Failed!\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm alicesTExtFilename.txt \n",
    "!hdfs dfs -copyFromLocal alicesTExtFilename.txt \n",
    "!hdfs dfs -rm -r cur_key-output\n",
    "#usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/tools/lib\n",
    "dataDir = \"/home/cloudera/Dropbox/DataScienceProgram/Day2\"\n",
    "\n",
    "!hadoop jar /usr/lib/hadoop-0.20-mapreduce/contrib/streaming/hadoop-streaming-2.6.0-mr1-cdh5.8.0.jar \\\n",
    "   -file \"/home/cloudera/Dropbox/DataScienceProgram/Day2/HWDay2/mapperlower.py\" \\\n",
    "   -mapper /home/cloudera/Dropbox/DataScienceProgram/Day2/HWDay2/mapperlower.py \\\n",
    "   -file \"/home/cloudera/Dropbox/DataScienceProgram/Day2/HWDay2/reducer2.py\" \\\n",
    "   -reducer /home/cloudera/Dropbox/DataScienceProgram/Day2/HWDay2/reducer2.py \\\n",
    "   -combiner /home/cloudera/Dropbox/DataScienceProgram/Day2/HWDay2/reducer2.py \\\n",
    "   -input alicesTExtFilename.txt \\\n",
    "   -output cur_key-output  \\\n",
    "   -numReduceTasks 3\n",
    "   #--D mapreduce.job.reduces=2  depecated\n",
    "#-input historical_tours.txt  file on Hadoop\n",
    "\n",
    "\n",
    "#output directory on Hadoop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-71-3ee0e3edc958>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-71-3ee0e3edc958>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    3. HW2.3\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "3. HW2.3\n",
    "\n",
    "The data file at http://www.metoffice.gov.uk/climate/uk/stationdata/heathrowdata.txt (mirrored here) is part of a \n",
    "set of text files cataloguing temperatures collected in different cities of the UK. The one for the URL given is for \n",
    "Heathrow (London Airport). Typically each city is held in one data file. You can access the whole set from here. \n",
    "Write a MapReduce application with a mapper.py and reduce.py that uses only the text file for Heathrow as input and \n",
    "that outputs the lowest temperature ever recorded and the year this event happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   292  100   292    0     0    169      0  0:00:01  0:00:01 --:--:--   215\n"
     ]
    }
   ],
   "source": [
    "!curl 'http://www.metoffice.gov.uk/climate/uk/stationdata/heathrowdata.txt' -o heathrowdata.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\r\n",
      "<html><head>\r\n",
      "<title>301 Moved Permanently</title>\r\n",
      "</head><body>\r\n",
      "<h1>Moved Permanently</h1>\r\n",
      "<p>The document has moved <a href=\"http://www.metoffice.gov.uk/pub/data/weather/uk/climate/stationdata/heathrowdata.txt\">here</a>.</p>\r\n",
      "</body></html>\r\n"
     ]
    }
   ],
   "source": [
    "!head heathrowdata.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
